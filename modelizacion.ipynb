{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fase de Modelización "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga del modelo MovilNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este primer punto vamos a cargar el modelo MovilNet para iniciar la fase de entrenamiento del modelo con los datos obtenidos en la fase de preanalisis y resolución. Luego probaremos una segunda parte con una CNN creada desde cero para contrastar resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importamos las librerias que necesitamos para instanciar el modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "IPython.notebook.kernel.restart()",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Javascript\n",
    "\n",
    "display(Javascript('IPython.notebook.kernel.restart()'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run imports.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52230, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model = pd.read_csv(\"output\\set_aumentado_v01.csv\")\n",
    "df_model.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Codificando imagenes: 52230it [07:46, 112.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of images: (52230, 244, 244, 3)\n",
      "Shape of labels: (52230, 5)\n"
     ]
    }
   ],
   "source": [
    "def image_label_load(data): \n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for image_path, label in tqdm(zip(data['path_files'].tolist(), data['label'].tolist()), desc=\"Codificando imagenes\"):\n",
    "        try: \n",
    "            img = Image.open(image_path).resize((244,244)).convert('RGB')\n",
    "            images.append(np.array(img))\n",
    "            labels.append(np.array(label))\n",
    "        except Exception as e: \n",
    "            print(f\"{e} Levantado tras ejecutar la ruta {image_path}\")\n",
    "    \n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "images, labels = image_label_load(df_model)\n",
    "\n",
    "# Codificar las etiquetas\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "labels_encoded = to_categorical(labels_encoded, num_classes=5)  # Asegúrate de especificar 5 clases\n",
    "\n",
    "print(f\"Shape of images: {images.shape}\")\n",
    "print(f\"Shape of labels: {labels_encoded.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varel\\AppData\\Local\\Temp\\ipykernel_6648\\3325738747.py:2: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(244,244,3))\n"
     ]
    }
   ],
   "source": [
    "# Carga del MobileNetV2\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(244,244,3))\n",
    "\n",
    "# Congelar capas base del modelo -> Conserva los pesos establecidos por el aprendizaje de imagenet\n",
    "base_model.trainable = False \n",
    "\n",
    "#Añadimos capas superiores para ajustar el modelo a nuestro caso concreto: \n",
    "\n",
    "x = base_model.output \n",
    "x = GlobalAveragePooling2D()(x) \n",
    "x = Dense(128, activation='relu')(x) \n",
    "\n",
    "predictions = Dense(5, activation='softmax')(x) # Ajuste para 5 clases (menu, outside, drink, inside, food)\n",
    "\n",
    "# Instancia del MobileNetV2 + capas superiores \n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compilacion del modelo en conjunto: \n",
    "\n",
    "model.compile(optimizer ='adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 26.1 GiB for an array with shape (39172, 244, 244, 3) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m datagen \u001b[38;5;241m=\u001b[39m ImageDataGenerator()\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Ajustamos el generador de datos al conjunto de entrenamiento \u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[43mdatagen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\varel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:1488\u001b[0m, in \u001b[0;36mImageDataGenerator.fit\u001b[1;34m(self, x, augment, rounds, seed)\u001b[0m\n\u001b[0;32m   1462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, augment\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1463\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fits the data generator to some sample data.\u001b[39;00m\n\u001b[0;32m   1464\u001b[0m \n\u001b[0;32m   1465\u001b[0m \u001b[38;5;124;03m    This computes the internal data stats related to the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1486\u001b[0m \u001b[38;5;124;03m        seed: Int (default: None). Random seed.\u001b[39;00m\n\u001b[0;32m   1487\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1488\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1489\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[0;32m   1490\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1491\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput to `.fit()` should have rank 4. Got array with shape: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1492\u001b[0m             \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m   1493\u001b[0m         )\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 26.1 GiB for an array with shape (39172, 244, 244, 3) and data type float32"
     ]
    }
   ],
   "source": [
    "# Train/Test split -> Division  de conjuntos de datos en entrenamiento y validacion \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels_encoded, test_size=0.25, random_state=41)\n",
    "\n",
    "\n",
    "# Data Augmentation --> para ganar mas variedad de datos a la hora de entrenar \n",
    "\"\"\"\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    "\"\"\"\n",
    "                ### HIPER-PARAMETROS DE DATA AUGMENTATION PARA ENTRENAMIENTO ###\n",
    "datagen = ImageDataGenerator()\n",
    "# Ajustamos el generador de datos al conjunto de entrenamiento \n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m572s\u001b[0m 1s/step - accuracy: 0.7466 - loss: 0.7189 - val_accuracy: 0.8042 - val_loss: 0.5134\n",
      "Epoch 2/10\n",
      "\u001b[1m  1/445\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:40\u001b[0m 902ms/step - accuracy: 0.9375 - loss: 0.3731"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 302ms/step - accuracy: 0.9375 - loss: 0.3731 - val_accuracy: 0.7876 - val_loss: 0.5470\n",
      "Epoch 3/10\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m541s\u001b[0m 1s/step - accuracy: 0.8341 - loss: 0.4596 - val_accuracy: 0.8276 - val_loss: 0.4660\n",
      "Epoch 4/10\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 303ms/step - accuracy: 0.8125 - loss: 0.4949 - val_accuracy: 0.8331 - val_loss: 0.4631\n",
      "Epoch 5/10\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m542s\u001b[0m 1s/step - accuracy: 0.8539 - loss: 0.4069 - val_accuracy: 0.8257 - val_loss: 0.4751\n",
      "Epoch 6/10\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 301ms/step - accuracy: 0.8750 - loss: 0.4282 - val_accuracy: 0.8238 - val_loss: 0.4819\n",
      "Epoch 7/10\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m543s\u001b[0m 1s/step - accuracy: 0.8639 - loss: 0.3794 - val_accuracy: 0.8440 - val_loss: 0.4356\n",
      "Epoch 8/10\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 300ms/step - accuracy: 0.8438 - loss: 0.2885 - val_accuracy: 0.8421 - val_loss: 0.4408\n",
      "Epoch 9/10\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m544s\u001b[0m 1s/step - accuracy: 0.8731 - loss: 0.3483 - val_accuracy: 0.8200 - val_loss: 0.4787\n",
      "Epoch 10/10\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 303ms/step - accuracy: 0.7188 - loss: 0.5219 - val_accuracy: 0.8242 - val_loss: 0.4657\n"
     ]
    }
   ],
   "source": [
    "# Numero de pasos por epoch\n",
    "batch_size = 32\n",
    "steps_per_epoch = len(X_train) // batch_size\n",
    "# Entrenar el modelo\n",
    "history = model.fit(datagen.flow(X_train, y_train, batch_size=batch_size),\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    epochs=10,\n",
    "                    validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 70/409\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:52\u001b[0m 1s/step"
     ]
    }
   ],
   "source": [
    "# Predicciones en el conjunto de prueba\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "\n",
    "# Calcular el F1-score\n",
    "f1 = f1_score(y_true_classes, y_pred_classes, average='weighted')\n",
    "print(f'F1-score: {f1}')\n",
    "\n",
    "# Calcular el accuracy\n",
    "accuracy = accuracy_score(y_true_classes, y_pred_classes)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "# Generar el reporte de clasificación\n",
    "report = classification_report(y_true_classes, y_pred_classes, target_names=label_encoder.classes_)\n",
    "print(report)\n",
    "\n",
    "# Generar la curva ROC y el AUC para cada clase\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(5):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plotear todas las curvas ROC\n",
    "plt.figure()\n",
    "colors = ['aqua', 'darkorange', 'cornflowerblue', 'green', 'red']\n",
    "for i, color in zip(range(5), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "             label=f'ROC curve (area = {roc_auc[i]:.2f}) for class {i}')\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0]) # apuntar \n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
